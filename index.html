<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.17.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:O,mm:h}=window,M=new O.Toolbar;M.attach(h);const oe=M.render();oe.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(oe)})})()</script><script>((i,L,f,r)=>{const w=i();window.mm=w.Markmap.create("svg#mindmap",(L||w.deriveOptions)(r),f)})(()=>window.markmap,null,{"content":"Guide Détaillé d'Application des Recommandations de Sécurité pour Systèmes d'IA selon l’Anssi","children":[{"content":"R1: Intégrer la sécurité dans toutes les phases du cycle de vie d’un système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Adopter une approche holistique où la sécurité est considérée dès la phase de conception et continue d'être une priorité à chaque étape du développement, du déploiement et de l'exploitation.","children":[],"payload":{"lines":"4,5"}}],"payload":{"lines":"3,4"}},{"content":"Exemples","children":[{"content":"Intégrer des outils de sécurité automatisés dans le pipeline de développement continu (CI/CD).","children":[],"payload":{"lines":"6,7"}},{"content":"Effectuer des audits de sécurité réguliers et des revues de code par des experts en sécurité.","children":[],"payload":{"lines":"7,9"}}],"payload":{"lines":"5,6"}}],"payload":{"lines":"2,3"}},{"content":"R2: Mener une analyse de risque sur les systèmes d’IA avant la phase d’entraînement","children":[{"content":"Façon de faire","children":[{"content":"Réaliser une évaluation des risques spécifique au projet d'IA qui inclut l'identification des vulnérabilités potentielles des données et des modèles.","children":[],"payload":{"lines":"11,12"}}],"payload":{"lines":"10,11"}},{"content":"Exemples","children":[{"content":"Utilisation de frameworks d'analyse de risques tels que OCTAVE ou FAIR pour évaluer les risques associés aux données et infrastructures d'IA.","children":[],"payload":{"lines":"13,14"}},{"content":"Cartographie des risques liés à la sécurité des données et des infrastructures avant de commencer l'entraînement des modèles.","children":[],"payload":{"lines":"14,16"}}],"payload":{"lines":"12,13"}}],"payload":{"lines":"9,10"}},{"content":"R3: Évaluer le niveau de confiance des bibliothèques et modules externes utilisés dans le système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Vérifier les licences, la popularité, les mises à jour de sécurité, et les revues de vulnérabilité des composants externes.","children":[],"payload":{"lines":"18,19"}}],"payload":{"lines":"17,18"}},{"content":"Exemples","children":[{"content":"Utiliser des outils comme GitHub Dependabot pour surveiller et mettre à jour les dépendances de sécurité.","children":[],"payload":{"lines":"20,21"}},{"content":"Choisir des bibliothèques avec un bon suivi de maintenance et une communauté active.","children":[],"payload":{"lines":"21,23"}}],"payload":{"lines":"19,20"}}],"payload":{"lines":"16,17"}},{"content":"R4: Évaluer le niveau de confiance des sources de données externes utilisées dans le système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Mettre en place des processus d'évaluation et de certification des fournisseurs de données, incluant des audits réguliers et des contrôles de qualité des données.","children":[],"payload":{"lines":"25,26"}}],"payload":{"lines":"24,25"}},{"content":"Exemples","children":[{"content":"Établir des partenariats avec des fournisseurs de données ayant des certifications de sécurité reconnues.","children":[],"payload":{"lines":"27,28"}},{"content":"Réaliser des tests de qualité et d'intégrité des données avant leur utilisation.","children":[],"payload":{"lines":"28,30"}}],"payload":{"lines":"26,27"}}],"payload":{"lines":"23,24"}},{"content":"R5: Appliquer les principes de DevSecOps sur l’ensemble des phases du projet","children":[{"content":"Façon de faire","children":[{"content":"Intégrer des pratiques de sécurité dans les processus de développement et d'opération pour une collaboration continue entre les équipes de développement, de sécurité, et d'opérations.","children":[],"payload":{"lines":"32,33"}}],"payload":{"lines":"31,32"}},{"content":"Exemples","children":[{"content":"Automatiser les scans de sécurité dans les pipelines CI/CD.","children":[],"payload":{"lines":"34,35"}},{"content":"Former les développeurs et opérateurs aux principes de sécurité fondamentaux et avancés.","children":[],"payload":{"lines":"35,37"}}],"payload":{"lines":"33,34"}}],"payload":{"lines":"30,31"}},{"content":"R6: Utiliser des formats de modèles d’IA sécurisés","children":[{"content":"Façon de faire","children":[{"content":"Sélectionner des formats qui supportent nativement des fonctionnalités de sécurité telles que le chiffrement et la signature numérique.","children":[],"payload":{"lines":"39,40"}}],"payload":{"lines":"38,39"}},{"content":"Exemples","children":[{"content":"Choisir des plateformes et des outils qui permettent le chiffrement des modèles lors du stockage et du transfert.","children":[],"payload":{"lines":"41,42"}},{"content":"Utiliser des formats de fichier qui intègrent des vérifications d'intégrité pour éviter les manipulations.","children":[],"payload":{"lines":"42,44"}}],"payload":{"lines":"40,41"}}],"payload":{"lines":"37,38"}},{"content":"R7: Prendre en compte les enjeux de confidentialité des données dès la conception du système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Adopter une approche de protection des données par défaut et par conception, intégrant la confidentialité dans les spécifications du système dès le début.","children":[],"payload":{"lines":"46,47"}}],"payload":{"lines":"45,46"}},{"content":"Exemples","children":[{"content":"Appliquer des techniques de minimisation des données, telles que le masquage ou la pseudonymisation.","children":[],"payload":{"lines":"48,49"}},{"content":"Implémenter des contrôles d'accès basés sur les rôles pour limiter l'accès aux données sensibles.","children":[],"payload":{"lines":"49,51"}}],"payload":{"lines":"47,48"}}],"payload":{"lines":"44,45"}},{"content":"R8: Prendre en compte la problématique de besoin d’en connaître dès la conception du système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Intégrer des contrôles d'accès stricts basés sur le principe du moindre privilège, où l'accès aux informations est limité au strict nécessaire pour accomplir une tâche spécifique.","children":[],"payload":{"lines":"53,54"}}],"payload":{"lines":"52,53"}},{"content":"Exemples","children":[{"content":"Développer et mettre en œuvre des politiques de sécurité qui définissent clairement qui peut accéder à quelles données et dans quelles circonstances.","children":[],"payload":{"lines":"55,56"}},{"content":"Utilisation de systèmes de gestion des identités et des accès (IAM) pour contrôler l'accès aux ressources dans les infrastructures d'IA.","children":[],"payload":{"lines":"56,58"}}],"payload":{"lines":"54,55"}}],"payload":{"lines":"51,52"}},{"content":"R9: Proscrire l’usage automatisé de systèmes d’IA pour des actions critiques sur le SI","children":[{"content":"Façon de faire","children":[],"payload":{"lines":"59,60"}},{"content":"Exemples","children":[{"content":"Mettre en place des protocoles où les décisions automatisées par l'IA doivent être vérifiées ou approuvées par un opérateur humain avant d'être exécutées.","children":[],"payload":{"lines":"62,63"}},{"content":"Utiliser des systèmes de détection d'anomalies pour alerter les superviseurs en cas de comportement non attendu de l'IA.","children":[],"payload":{"lines":"63,65"}}],"payload":{"lines":"61,62"}}],"payload":{"lines":"58,59"}},{"content":"R10: Maîtriser et sécuriser les accès à privilèges des développeurs et des administrateurs sur le système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Utiliser des pratiques de gestion des accès à privilèges, telles que le contrôle d'accès basé sur les rôles (RBAC) et la vérification régulière des droits d'accès.","children":[],"payload":{"lines":"67,68"}}],"payload":{"lines":"66,67"}},{"content":"Exemples","children":[{"content":"Mise en œuvre de solutions de gestion des privilèges pour surveiller et contrôler l'accès aux systèmes critiques.","children":[],"payload":{"lines":"69,70"}},{"content":"Réaliser des audits de sécurité fréquents pour s'assurer que seules les personnes autorisées ont accès à des informations sensibles ou critiques.","children":[],"payload":{"lines":"70,72"}}],"payload":{"lines":"68,69"}}],"payload":{"lines":"65,66"}},{"content":"R11: Héberger le système d’IA dans des environnements de confiance cohérents avec les besoins de sécurité","children":[{"content":"Façon de faire","children":[{"content":"Sélectionner des environnements d'hébergement qui répondent aux normes de sécurité établies et qui sont compatibles avec les exigences spécifiques du système d'IA.","children":[],"payload":{"lines":"74,75"}}],"payload":{"lines":"73,74"}},{"content":"Exemples","children":[{"content":"Choisir des fournisseurs de cloud qui offrent des certifications de sécurité reconnues.","children":[],"payload":{"lines":"76,77"}},{"content":"Utiliser des technologies de virtualisation sécurisées pour isoler le système d'IA des autres systèmes.","children":[],"payload":{"lines":"77,79"}}],"payload":{"lines":"75,76"}}],"payload":{"lines":"72,73"}},{"content":"R12: Cloisonner chaque phase du système d’IA dans un environnement dédié","children":[{"content":"Façon de faire","children":[{"content":"Utiliser des environnements virtuels séparés pour les différentes phases du cycle de vie du système d'IA, telles que le développement, le test, et la production.","children":[],"payload":{"lines":"81,82"}}],"payload":{"lines":"80,81"}},{"content":"Exemples","children":[{"content":"Mettre en place des serveurs de développement, de test et de production distincts pour éviter les contaminations croisées.","children":[],"payload":{"lines":"83,84"}},{"content":"Utiliser des conteneurs pour isoler les environnements d'exécution de l'IA.","children":[],"payload":{"lines":"84,86"}}],"payload":{"lines":"82,83"}}],"payload":{"lines":"79,80"}},{"content":"R13: Implémenter une passerelle Internet sécurisée dans le cas d’un système d’IA exposé sur Internet","children":[{"content":"Façon de faire","children":[{"content":"Déployer des passerelles de sécurité, comme des pare-feu d'applications web (WAF) et des systèmes de prévention d'intrusion (IPS), pour surveiller et contrôler le trafic entrant et sortant.","children":[],"payload":{"lines":"88,89"}}],"payload":{"lines":"87,88"}},{"content":"Exemples","children":[{"content":"Installer et configurer un WAF pour protéger les applications d'IA accessibles via Internet.","children":[],"payload":{"lines":"90,91"}},{"content":"Mettre en œuvre des règles strictes de filtrage de trafic pour limiter l'accès aux ressources d'IA aux utilisateurs autorisés.","children":[],"payload":{"lines":"91,93"}}],"payload":{"lines":"89,90"}}],"payload":{"lines":"86,87"}},{"content":"R14: Privilégier un hébergement SecNumCloud dans le cas d’un déploiement d’un système d’IA dans un Cloud public","children":[{"content":"Façon de faire","children":[{"content":"Opter pour des services de cloud qui offrent un niveau élevé de sécurité et qui sont certifiés par des normes nationales ou internationales.","children":[],"payload":{"lines":"95,96"}}],"payload":{"lines":"94,95"}},{"content":"Exemples","children":[{"content":"Sélectionner des fournisseurs de cloud qui sont certifiés SecNumCloud, assurant ainsi que l'infrastructure répond à des critères de sécurité stricts.","children":[],"payload":{"lines":"97,98"}},{"content":"Évaluer régulièrement la conformité des services de cloud utilisés pour s'assurer qu'ils maintiennent les standards requis.","children":[],"payload":{"lines":"98,100"}}],"payload":{"lines":"96,97"}}],"payload":{"lines":"93,94"}},{"content":"R15: Prévoir un mode dégradé des services métier sans système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Concevoir les systèmes de manière à ce qu'ils puissent continuer à fonctionner, même de façon réduite, sans la composante d'IA, afin de garantir la continuité des opérations en cas de défaillance.","children":[],"payload":{"lines":"102,103"}}],"payload":{"lines":"101,102"}},{"content":"Exemples","children":[{"content":"Développer des procédures opérationnelles standard qui permettent aux processus métier de continuer sans l'aide de l'IA.","children":[],"payload":{"lines":"104,105"}},{"content":"Tester régulièrement le mode dégradé pour s'assurer de son efficacité en cas de besoin.","children":[],"payload":{"lines":"105,107"}}],"payload":{"lines":"103,104"}}],"payload":{"lines":"100,101"}},{"content":"R16: Dédier les composants GPU au système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Allouer des ressources matérielles, comme les GPU, exclusivement pour l'usage des systèmes d'IA pour améliorer les performances et la sécurité.","children":[],"payload":{"lines":"109,110"}}],"payload":{"lines":"108,109"}},{"content":"Exemples","children":[{"content":"Configurer des serveurs dédiés avec des GPU réservés uniquement pour le traitement et l'analyse d'IA.","children":[],"payload":{"lines":"111,112"}},{"content":"Mettre en œuvre des politiques de sécurité pour protéger ces ressources matérielles critiques contre les accès non autorisés.","children":[],"payload":{"lines":"112,114"}}],"payload":{"lines":"110,111"}}],"payload":{"lines":"107,108"}},{"content":"R17: Prendre en compte les attaques par canaux auxiliaires sur le système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Évaluer et mitiger les risques liés aux attaques par canaux auxiliaires, qui exploitent des informations indirectes (comme la consommation d'énergie ou le temps de calcul) pour extraire des données sensibles.","children":[],"payload":{"lines":"116,117"}}],"payload":{"lines":"115,116"}},{"content":"Exemples","children":[{"content":"Implémenter des mesures de sécurité pour masquer ou randomiser les signatures de traitement qui pourraient être exploitées.","children":[],"payload":{"lines":"118,119"}},{"content":"Réaliser des audits de sécurité réguliers pour détecter et adresser les vulnérabilités aux attaques par canaux auxiliaires.","children":[],"payload":{"lines":"119,121"}}],"payload":{"lines":"117,118"}}],"payload":{"lines":"114,115"}},{"content":"R18: Entraîner un modèle d’IA uniquement avec des données légitimement accessibles par les utilisateurs","children":[{"content":"Façon de faire","children":[{"content":"S'assurer que toutes les données utilisées pour l'entraînement des modèles d'IA sont obtenues et traitées conformément aux droits d'accès et aux réglementations en vigueur.","children":[],"payload":{"lines":"123,124"}}],"payload":{"lines":"122,123"}},{"content":"Exemples","children":[{"content":"Mettre en place des politiques strictes de gestion des données qui garantissent que seules les données autorisées sont utilisées pour l'entraînement.","children":[],"payload":{"lines":"125,126"}},{"content":"Effectuer des vérifications périodiques des ensembles de données pour s'assurer de leur conformité légale et éthique.","children":[],"payload":{"lines":"126,128"}}],"payload":{"lines":"124,125"}}],"payload":{"lines":"121,122"}},{"content":"R19: Protéger en intégrité les données d’entraînement du modèle d’IA","children":[{"content":"Façon de faire","children":[{"content":"Utiliser des techniques de protection des données telles que le chiffrement et les contrôles d'intégrité pour sécuriser les données d'entraînement contre les modifications non autorisées.","children":[],"payload":{"lines":"130,131"}}],"payload":{"lines":"129,130"}},{"content":"Exemples","children":[{"content":"Chiffrer les ensembles de données d'entraînement stockés sur des serveurs ou transférés sur des réseaux.","children":[],"payload":{"lines":"132,133"}},{"content":"Utiliser des checksums ou des signatures numériques pour vérifier l'intégrité des données d'entraînement.","children":[],"payload":{"lines":"133,135"}}],"payload":{"lines":"131,132"}}],"payload":{"lines":"128,129"}},{"content":"R20: Protéger en intégrité les fichiers du système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Assurer que les fichiers essentiels au fonctionnement des systèmes d'IA ne sont pas altérés, en utilisant des mécanismes comme le chiffrement, les signatures numériques et les audits réguliers.","children":[],"payload":{"lines":"137,138"}}],"payload":{"lines":"136,137"}},{"content":"Exemples","children":[{"content":"Mettre en œuvre des systèmes de détection d'intégrité des fichiers comme les solutions de File Integrity Monitoring (FIM).","children":[],"payload":{"lines":"139,140"}},{"content":"Chiffrer les fichiers de configuration et les scripts utilisés par les systèmes d'IA.","children":[],"payload":{"lines":"140,142"}}],"payload":{"lines":"138,139"}}],"payload":{"lines":"135,136"}},{"content":"R21: Proscrire le ré-entraînement du modèle d’IA en production","children":[{"content":"Façon de faire","children":[{"content":"Établir des procédures opérationnelles qui interdisent la modification ou le ré-entraînement des modèles d'IA dans l'environnement de production, pour prévenir les risques de sécurité introduits par des modifications non contrôlées.","children":[],"payload":{"lines":"144,145"}}],"payload":{"lines":"143,144"}},{"content":"Exemples","children":[{"content":"Configurer les systèmes d'IA pour désactiver les capacités de ré-entraînement automatique ou manuel en production.","children":[],"payload":{"lines":"146,147"}},{"content":"Effectuer toutes les mises à jour ou ré-entraînements dans un environnement de développement sécurisé et contrôlé.","children":[],"payload":{"lines":"147,149"}}],"payload":{"lines":"145,146"}}],"payload":{"lines":"142,143"}},{"content":"R22: Sécuriser la chaîne de déploiement en production des systèmes d’IA","children":[{"content":"Façon de faire","children":[{"content":"Mettre en place des contrôles de sécurité tout au long de la chaîne de déploiement pour s'assurer que les artefacts de déploiement sont sécurisés et vérifiés à chaque étape.","children":[],"payload":{"lines":"151,152"}}],"payload":{"lines":"150,151"}},{"content":"Exemples","children":[{"content":"Utiliser des pipelines de déploiement automatisés avec des étapes de vérification de sécurité intégrées, comme des scans de vulnérabilités et des contrôles de conformité.","children":[],"payload":{"lines":"153,154"}},{"content":"Exiger des approbations manuelles par plusieurs parties avant toute mise en production.","children":[],"payload":{"lines":"154,156"}}],"payload":{"lines":"152,153"}}],"payload":{"lines":"149,150"}},{"content":"R23: Prévoir des audits de sécurité des systèmes d’IA avant déploiement en production","children":[{"content":"Façon de faire","children":[{"content":"Planifier et exécuter des audits de sécurité complets avant de déployer les systèmes d'IA en production pour identifier et corriger d'éventuelles failles de sécurité.","children":[],"payload":{"lines":"158,159"}}],"payload":{"lines":"157,158"}},{"content":"Exemples","children":[{"content":"Engager des auditeurs externes pour effectuer des évaluations de sécurité indépendantes.","children":[],"payload":{"lines":"160,161"}},{"content":"Réaliser des tests de pénétration et des évaluations de vulnérabilité spécifiques aux applications d'IA.","children":[],"payload":{"lines":"161,163"}}],"payload":{"lines":"159,160"}}],"payload":{"lines":"156,157"}},{"content":"R24: Prévoir des tests fonctionnels métier des systèmes d’IA avant déploiement en production","children":[{"content":"Façon de faire","children":[{"content":"Conduire des tests fonctionnels approfondis pour vérifier que les systèmes d'IA remplissent correctement les fonctions métier pour lesquelles ils ont été conçus, dans un environnement simulant la production.","children":[],"payload":{"lines":"165,166"}}],"payload":{"lines":"164,165"}},{"content":"Exemples","children":[{"content":"Effectuer des simulations de scénarios métier réels pour tester la performance et la fiabilité des systèmes d'IA.","children":[],"payload":{"lines":"167,168"}},{"content":"Inclure les parties prenantes métier dans le processus de validation pour s'assurer que les systèmes répondent aux exigences pratiques.","children":[],"payload":{"lines":"168,170"}}],"payload":{"lines":"166,167"}}],"payload":{"lines":"163,164"}},{"content":"R25: Protéger le système d’IA en filtrant les entrées et les sorties des utilisateurs","children":[{"content":"Façon de faire","children":[],"payload":{"lines":"171,172"}},{"content":"Exemples","children":[{"content":"Utiliser des firewalls d'applications web (WAF) pour inspecter et filtrer le trafic entrant et sortant du système d'IA.","children":[],"payload":{"lines":"174,175"}},{"content":"Appliquer des politiques de validation des données pour s'assurer que toutes les entrées et sorties passent par des contrôles de sécurité rigoureux.","children":[],"payload":{"lines":"175,176"}}],"payload":{"lines":"173,174"}}],"payload":{"lines":"170,171"}},{"content":"R26: Maîtriser et sécuriser les interactions du système d’IA avec d’autres applications métier","children":[{"content":"Façon de faire","children":[{"content":"Établir des protocoles stricts pour les intégrations API et autres interfaces de communication entre l'IA et les applications métier, pour prévenir les interférences non autorisées et les failles de sécurité.","children":[],"payload":{"lines":"178,179"}}],"payload":{"lines":"177,178"}},{"content":"Exemples","children":[{"content":"Utiliser des API sécurisées avec des méthodes d'authentification robustes telles que OAuth 2.0.","children":[],"payload":{"lines":"180,181"}},{"content":"Mettre en œuvre des audits réguliers des interfaces pour détecter et corriger les vulnérabilités.","children":[],"payload":{"lines":"181,183"}}],"payload":{"lines":"179,180"}}],"payload":{"lines":"176,177"}},{"content":"R27: Limiter les actions automatiques depuis un système d’IA traitant des entrées non-maîtrisées","children":[{"content":"Façon de faire","children":[{"content":"Définir des règles qui limitent les décisions automatiques de l'IA, surtout lorsque les données d'entrée peuvent être imprévisibles ou non vérifiées.","children":[],"payload":{"lines":"185,186"}}],"payload":{"lines":"184,185"}},{"content":"Exemples","children":[{"content":"Configurer des seuils pour les actions automatiques qui nécessitent une validation humaine pour des scénarios critiques.","children":[],"payload":{"lines":"187,188"}},{"content":"Implémenter des mécanismes de surveillance pour alerter les opérateurs en cas de comportement anormal de l'IA.","children":[],"payload":{"lines":"188,190"}}],"payload":{"lines":"186,187"}}],"payload":{"lines":"183,184"}},{"content":"R28: Cloisonner le système d’IA dans un ou plusieurs environnements techniques dédiés","children":[{"content":"Façon de faire","children":[{"content":"Utiliser la virtualisation ou des conteneurs pour isoler physiquement et logiquement le système d’IA des autres systèmes et réseaux de l'entreprise.","children":[],"payload":{"lines":"192,193"}}],"payload":{"lines":"191,192"}},{"content":"Exemples","children":[{"content":"Utiliser des machines virtuelles (VM) ou des conteneurs Docker pour exécuter des instances d'IA dans des environnements isolés.","children":[],"payload":{"lines":"194,195"}},{"content":"Mettre en place des réseaux virtuels privés (VPC) spécifiques pour les opérations d'IA.","children":[],"payload":{"lines":"195,197"}}],"payload":{"lines":"193,194"}}],"payload":{"lines":"190,191"}},{"content":"R29: Journaliser l’ensemble des traitements réalisés au sein du système d’IA","children":[{"content":"Façon de faire","children":[{"content":"Mettre en œuvre une politique de journalisation complète qui capture tous les traitements de données, décisions et actions réalisées par le système d'IA.","children":[],"payload":{"lines":"199,200"}}],"payload":{"lines":"198,199"}},{"content":"Exemples","children":[{"content":"Configurer des logs détaillés qui enregistrent chaque action et décision prise par l'IA.","children":[],"payload":{"lines":"201,202"}},{"content":"Utiliser des outils de gestion de logs centralisés pour surveiller et analyser les activités de l'IA.","children":[],"payload":{"lines":"202,204"}}],"payload":{"lines":"200,201"}}],"payload":{"lines":"197,198"}},{"content":"R30: Contrôler systématiquement le code source généré par IA","children":[{"content":"Façon de faire","children":[{"content":"Mettre en place des revues de code et des vérifications de sécurité pour tout code source automatiquement généré par des systèmes d'IA avant son utilisation en production.","children":[],"payload":{"lines":"206,207"}}],"payload":{"lines":"205,206"}},{"content":"Exemples","children":[{"content":"Organiser des revues de code manuelles pour le code généré par l'IA.","children":[],"payload":{"lines":"208,209"}},{"content":"Utiliser des outils de scanning de sécurité automatique pour détecter les vulnérabilités dans le code généré.","children":[],"payload":{"lines":"209,211"}}],"payload":{"lines":"207,208"}}],"payload":{"lines":"204,205"}},{"content":"R31: Limiter la génération de code source par IA pour des modules critiques d’applications","children":[{"content":"Façon de faire","children":[{"content":"Restreindre ou interdire l'utilisation de code source généré automatiquement par l'IA dans les composants critiques de sécurité ou de fonctionnalité.","children":[],"payload":{"lines":"213,214"}}],"payload":{"lines":"212,213"}},{"content":"Exemples","children":[{"content":"Définir des politiques spécifiant les domaines où le code généré par IA peut être utilisé et ceux où il est interdit.","children":[],"payload":{"lines":"215,216"}},{"content":"Utiliser uniquement du code manuellement écrit et minutieusement testé pour les fonctions critiques.","children":[],"payload":{"lines":"216,218"}}],"payload":{"lines":"214,215"}}],"payload":{"lines":"211,212"}},{"content":"R32: Sensibiliser les développeurs sur les risques liés au code source généré par IA","children":[{"content":"Façon de faire","children":[{"content":"Organiser des formations et des sessions d'information pour les développeurs sur les risques potentiels et les meilleures pratiques liées à l'utilisation du code généré par IA.","children":[],"payload":{"lines":"220,221"}}],"payload":{"lines":"219,220"}},{"content":"Exemples","children":[{"content":"Créer des modules de formation qui expliquent comment inspecter et sécuriser le code généré par IA.","children":[],"payload":{"lines":"222,223"}},{"content":"Intégrer des ateliers pratiques pour améliorer les compétences des développeurs dans la gestion des risques associés au code généré.","children":[],"payload":{"lines":"223,225"}}],"payload":{"lines":"221,222"}}],"payload":{"lines":"218,219"}},{"content":"R33: Durcir les mesures de sécurité pour des services d’IA grand public exposés sur Internet","children":[{"content":"Exemples","children":[{"content":"Mettre en place des solutions de pare-feu avancées, des systèmes de détection d'intrusion, et des protections DDoS.","children":[],"payload":{"lines":"229,230"}},{"content":"Effectuer des tests de stress et de pénétration réguliers sur les infrastructures publiques.","children":[],"payload":{"lines":"230,232"}}],"payload":{"lines":"228,229"}}],"payload":{"lines":"225,226"}},{"content":"R34: Proscrire l’utilisation d’outils d’IA générative sur Internet pour un usage professionnel impliquant des données sensibles","children":[{"content":"Façon de faire","children":[{"content":"Établir des directives claires interdisant l'utilisation d'outils d'IA générative accessibles via Internet pour traiter des données professionnelles sensibles.","children":[],"payload":{"lines":"234,235"}}],"payload":{"lines":"233,234"}},{"content":"Exemples","children":[{"content":"Formuler des politiques internes qui limitent l'accès à certaines catégories d'outils d'IA basés sur le cloud pour les données critiques.","children":[],"payload":{"lines":"236,237"}},{"content":"Mettre en place des contrôles d'accès et des audits réguliers pour surveiller l'utilisation des outils d'IA.","children":[],"payload":{"lines":"237,239"}}],"payload":{"lines":"235,236"}}],"payload":{"lines":"232,233"}},{"content":"R35: Effectuer une revue régulière de la configuration des droits des outils d’IA générative sur les applications métier","children":[{"content":"Façon de faire","children":[{"content":"Programmer des révisions périodiques des configurations et des permissions accordées aux outils d'IA pour assurer une adéquation continue avec les politiques de sécurité et les besoins métier.","children":[],"payload":{"lines":"241,242"}}],"payload":{"lines":"240,241"}},{"content":"Exemples","children":[{"content":"Utiliser des outils de gestion des configurations pour surveiller et ajuster les paramètres de sécurité des outils d'IA.","children":[],"payload":{"lines":"243,244"}},{"content":"Organiser des sessions d'audit de conformité pour évaluer l'adéquation des configurations des outils d'IA avec les exigences réglementaires et métier.","children":[],"payload":{"lines":"244,245"}}],"payload":{"lines":"242,243"}}],"payload":{"lines":"239,240"}}],"payload":{"lines":"0,1"}},null)</script>
</body>
</html>
